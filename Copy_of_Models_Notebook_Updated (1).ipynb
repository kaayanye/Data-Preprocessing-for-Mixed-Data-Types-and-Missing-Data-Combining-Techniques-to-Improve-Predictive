{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Models Notebook Updated.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and Dataset Initilization\n",
        "First we import the Python libraries we will be using:\n",
        "Numpy, Pandas, Seaborn, MatPlotLib and SKLearn and Prince. \n",
        "\n",
        "Prince will be used for the MCA and FAMD and may need to be installed first"
      ],
      "metadata": {
        "id": "emdRTyc6Jvau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prince\n",
        "!pip install -U scipy"
      ],
      "metadata": {
        "id": "qXrNf3XkaoMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOhEwER9RvCf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import prince\n",
        "import scipy\n",
        "import sklearn\n",
        "import xgboost\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy.special import boxcox1p\n",
        "from scipy import stats\n",
        "from math import ceil\n",
        "from scipy.stats import probplot\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LogisticRegression\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.preprocessing import power_transform\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn import metrics\n",
        "from numpy import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then this code allows the Google Drive to be mounted, such that we can work with files that we have located on Drive itself.\n",
        "\n",
        "Note: you will have to sign-in/grant access for this in a pop-up window"
      ],
      "metadata": {
        "id": "dF517duuKNiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "95QawHq5yRgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need the train.csv file, which is found under https://drive.google.com/file/d/1_PLO-CF84thdpb-dMlE8y24nEyH-g7qh/view?usp=sharing.\n",
        "\n",
        "In order to be able to read it, we use the file ID from the URL with /uc?id= to get a direct download like which can be saved as a pandas dataframe."
      ],
      "metadata": {
        "id": "Rehuxf5mK7BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://drive.google.com/file/d/1_PLO-CF84thdpb-dMlE8y24nEyH-g7qh/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "init_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "9--l3xSxSIYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you are running this locally, don't run the drive related blocks, but use the code block below"
      ],
      "metadata": {
        "id": "ZEuSil5pgUUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init_df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "WYV7O98igSM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we've imported the dataset, let's save it under the df variable (dataframe)"
      ],
      "metadata": {
        "id": "4jhQSTdIgdc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df is a copy of the initial df so we don't have to redownload many times\n",
        "df = init_df.copy()"
      ],
      "metadata": {
        "id": "eEoBR4C2RxQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **General Setup**\n",
        "\n",
        "Now that we have our dataset, let's setup the roadmap of what we want to achieve in this notebook. The goal here is to test different methods of preparing this data on different models. Let's quickly go over the preparation techniques and models.\n",
        "\n",
        "# Data Preparation\n",
        "Data preparation is concerned with adjusting the raw data to such an extent that it improves the performance of our models. This is mainly focused on the following aspects\n",
        "> **Preprocessing**\n",
        "\n",
        "> Preprocessing in this notebook is used to refer to the very basic form of preprocessing we want to apply to all the datasets. This includes basic steps to make the data usable for the models, including: Ordinal encoding, Nominal One-Hot Encoding and Processing Missing Data.\n",
        "\n",
        "> **Feature Engineering**\n",
        "\n",
        ">This is an additonal preprocessing step where we manually adjust features to improve our dataset. This is done by: Transforming Numerical Features with BoxCox, Log and Yeo-Johnson, Removing Multi-colinear features, engineering new features and removing outliers. \n",
        "\n",
        "\n",
        "> **Feature Selection**\n",
        "\n",
        ">This is an additional preprocessing step where we use L1 regularization recursively to regularize features with little predictive power out. This is an automated approach to the manual Feature engineering. \n",
        "\n",
        "> **Dimensionality Reduction**\n",
        "\n",
        ">Dimensionality reduction refers to lowering the amount of features to reduce the chance of overfitting. This is done with various different models, which all automatically reduce features according to similar principles. For Numeric data we have PCA, Nominal data MCA and for both there is FAMD.\n",
        "\n",
        "# Models\n",
        "Our models are our actual prediction algorithms which will use the prepared dataset to learn and then make predictions on the SalePrice for the validation/test set. The models consist of \n",
        "> LinearRegression, RidgeCV, LassoCV, AdaBoostRegressor, XGBoost\n",
        "\n",
        "#Structure\n",
        "In this Notebook, we want to test all the possible combinations of Data Preparation with the different Models. As such we will first introduce different sets of preprocessed data and functions to preprocess datasets. \n",
        "After this we will introduce the models we will be using, based on which we will find the best dataset for that model with respect to feature engineering and dimensionality reduction. \n",
        "Based on that we will test the combinations of all best preprocessing datasets with all the models.\n",
        "\n"
      ],
      "metadata": {
        "id": "C33brzocgq55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "# Preprocessing\n",
        "Let's define 3 categories on which we can seperate the features in our dataframe. This is useful for preprocessing the data and might be useful later on as well.\n",
        "\n",
        "\n",
        "> Nominal data: Data classified into different categories without ranking.\n",
        "\n",
        "> Ordinal data: Data classified into different categories with ranking.\n",
        "\n",
        "> Numeric data: Numeric data based on normally valued real numbers.\n",
        "\n",
        "\n",
        "Not Usable: The pool features have been deemed unusable (clarified in comments)\n"
      ],
      "metadata": {
        "id": "cLGig8ic7JSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First divide data into the numerical or categorical, so we can preprocess it\n",
        "\n",
        "# List of nominal and ordinal columns extracted from data_description.txt\n",
        "nom_col = ['MSSubClass', 'MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1',\n",
        "           'Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n",
        "           'BsmtFinType1','BsmtFinType2','Electrical','FireplaceQu','PavedDrive','Fence','SaleCondition',\n",
        "           'MasVnrType','Foundation','Heating','CentralAir','GarageType','SaleType','MiscFeature',\n",
        "           # Month sold and Year should be considered nominal, as they can have \n",
        "           # an effect on sale price (price fluctuations or whatever), but not\n",
        "           # on an ordinal scale\n",
        "           'MoSold' , 'YrSold'\n",
        "           ]\n",
        "\n",
        "ord_col = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\n",
        "           'HeatingQC','KitchenQual','Functional',\n",
        "           'GarageFinish','GarageQual','GarageCond','PoolQC','OverallQual','OverallCond',\n",
        "           # The following are added as ordinal features because they have a\n",
        "           # very low number of discrete categories, and it intuitively makes\n",
        "           # sense to consider 2 fullbaths better than 1.\n",
        "           'BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n",
        "           'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars'\n",
        "           ]\n",
        "\n",
        "# The following are not used and are left out on purpose. They contain only\n",
        "# 7 measurements, and far too many NaNs to easily be used.\n",
        "# Alternatively, they could be one-hot encoded so that abundance of NaN or '0'\n",
        "# will not impact the regression algorithms as negatively.\n",
        "# Another alternative could be to create a new nominal feature of whether a\n",
        "# house has a pool or not, or [no pool, average pool, nice pool].\n",
        "not_usable = ['PoolQC' , 'PoolArea',]\n",
        "\n",
        "# List of all columns\n",
        "allcat = list(df.columns[1:])\n",
        "\n",
        "# List of numerical columns\n",
        "num_col = [x for x in allcat if x not in nom_col+ord_col]\n",
        "print(num_col)"
      ],
      "metadata": {
        "id": "ysd9JaulR2nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have 3 categories to which we can classify our features, we come to the data pre-processing stage. \n",
        "\n",
        "Data pre-processing can be done in several ways, so let's first set up some functions which can help up with pre-processing.\n",
        "\n",
        "Impute: \n",
        ">Imputes (estimates) a number for a missing entry in the data. This is only done for LotFrontage. \n",
        "\n",
        "Fixnan: \n",
        ">Fixes some issues with after the Nans have been filled\n",
        "\n",
        "Fillnan: \n",
        ">Deals with the the missing data NaN, but replacing it with 'None' for our nominal and ordinal features and '0' for the numerical features\n",
        "\n",
        "PreProcess: \n",
        "> Drops the not_usable features from the dataframe, then applies fillnan and fixnan and splits up the data into the earlier defined features.\n",
        "\n",
        "> Then we apply one-hot encoding to the nominal features and manually map the ordinal features to ensure that the rankings for each feature are correctly covered.\n",
        "\n",
        ">Finally we merge the features together again to create a full preprocessed dataframe.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hdRcvlDN9qzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impute(input):\n",
        "    # Only used for LotFrontage to avoid too much imputation causeing inaccuracy\n",
        "    imp = IterativeImputer(n_nearest_features=None, imputation_order='ascending')\n",
        "    imp.fit(input)\n",
        "    output = pd.DataFrame(imp.transform(input), columns = input.columns)\n",
        "    return output\n",
        "\n",
        "\n",
        "def fixnan(input):\n",
        "    # Fix the garage year built - Inputting 0 would put it very far below all\n",
        "    # other houses, so instead if there is no garage, simply input the year\n",
        "    # the house was built in the garage year built column.\n",
        "    input.loc[input.GarageYrBlt.isnull(),'GarageYrBlt'] = input.loc[input.GarageYrBlt.isnull(),'YearBuilt']\n",
        "\n",
        "    # Drop the single row with NaN in 'Electrical' since this is a missing \n",
        "    # measurement. Additionally, drop the rows related to the masonry that\n",
        "    # contain NaN values, as these are also missing measurements, and there are\n",
        "    # only a few of them, less than 10 rows.\n",
        "    input.dropna(subset = ['Electrical','MasVnrType','MasVnrArea'], inplace=True)\n",
        "\n",
        "    # Fix MasVnrArea as it is for some reason an object type\n",
        "    input.MasVnrArea = input.MasVnrArea.astype(str).astype(float)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "def fillnan(input, remlf=1):\n",
        "    # Fill NaNs\n",
        "    for col in nom_col:\n",
        "        input[col].fillna('None',inplace=True)\n",
        "    for col in ord_col:\n",
        "        input[col].fillna('None',inplace=True)\n",
        "\n",
        "    # Remove LotFrontage from list of columns to fill. We don't want to fill \n",
        "    # this, as it is a continuous numerical measurement we can fill with \n",
        "    # multivariate imputation instead, to benefit our models accuracy\n",
        "    col_num_nan = num_col.copy()\n",
        "    if remlf is 1:\n",
        "        try: col_num_nan.remove('LotFrontage')\n",
        "        except: pass\n",
        "    for col in col_num_nan:\n",
        "        input[col].fillna('0',inplace=True)\n",
        "    return input\n",
        "\n",
        "\n",
        "def preprocess(df, remlf=1):\n",
        "    df.drop(not_usable, axis=1)\n",
        "    df = fixnan(df)\n",
        "    df = fillnan(df, remlf)\n",
        "\n",
        "    # Split nominal, ordinal, and numerical columns\n",
        "    df_nom = df[nom_col]\n",
        "    df_ord = df[ord_col]\n",
        "    df_num = df.drop(list(nom_col+ord_col), axis=1)\n",
        "\n",
        "    # One-hot encode nominal columns\n",
        "    df_nom = pd.get_dummies(data=df_nom)\n",
        "    df_MSSubClass = pd.get_dummies(data=df.MSSubClass, prefix='MSSubClass', prefix_sep='_')\n",
        "\n",
        "    # Map ordinal columns\n",
        "    df_ord.BsmtExposure = df_ord.BsmtExposure.replace({'NA' : 0, 'No' : 0, 'Mn' : 1, 'Av' : 2, 'Gd' : 3})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 5})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'None' : 0,  'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5})\n",
        "    df_ord = df_ord.replace({'IR3' : 0, 'IR2' : 1, 'IR1' : 2, 'Reg' : 3})\n",
        "    df_ord = df_ord.replace({'Low' : 0, 'HLS' : 1, 'Bnk' : 2, 'Lvl' : 3})\n",
        "    df_ord = df_ord.replace({'Gtl' : 0, 'Mod' : 1, 'Sev' : 2})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'Lwq' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6})\n",
        "    df_ord = df_ord.replace({'Sal' : 0, 'Sev' : 1, 'Maj2' : 2, 'Maj1' : 3, 'Mod' : 4, 'Min2' : 5, 'Min1' : 6, 'Typ' : 7})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3})\n",
        "    df_ord = df_ord.replace({'N' : 0, 'P' : 1, 'Y' : 2})\n",
        "    df_ord = df_ord.replace({'ELO' : 0, 'NoSeWa' : 1, 'NoSewr' : 2, 'AllPub' : 3})\n",
        "\n",
        "    # Merge nominal, ordinal, and numerical back together\n",
        "    df = pd.concat([df_num, df_MSSubClass, df_nom, df_ord], axis=1)\n",
        "    df = df.drop(\"MSSubClass\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "DRFrR8riR6hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have these functions defined, let's create a preprocessed dataset ppr_df. This will be the basis for the rest of our Data Preprocessing, as well as being 1 of the 8 datasets we want to test. "
      ],
      "metadata": {
        "id": "tJeH8OYYlnUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess, leave LotFrontage with NaN (to impute later)\n",
        "pp_df = preprocess(df)\n",
        "# Imput missing LotFrontage values\n",
        "ppr_df = impute(pp_df)\n",
        "# Dataset which only removes NaNs, labels columns for ordirnal/nominal data and int/float data for the Auto Sklearn dataset.\n",
        "ppr_auto_df = preprocess(df, remlf=0)\n",
        "ppr_auto_df['LotFrontage'] = ppr_auto_df['LotFrontage'].astype('int')"
      ],
      "metadata": {
        "id": "5b80o1_EUHpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "For Feature Engineering we want to perform a few steps to adjust the dataset. Let's make some formulas to perform each of these actions.\n",
        "\n",
        "Drop_Features\n",
        ">We remove one of every pair to prevent the problem of multicollinearity. Multicollinearity is when 2 or more independent variables are highly correlated with another. This negatively affects the model's ability to identify the most important features\n",
        ">We also remove features which have over 96% of a single value\n",
        "\n",
        "Remove_Outliers\n",
        ">We remove outliers for LotFrontage, LotArea, BsmtFinSF1, TotalBsmtSF and GrLivArea to ensure that the model is not too much affected by extreme values\n",
        "\n",
        "Add_Features\n",
        ">We add some new features based on what we know about other features, like calcultating the TotalPorch by addinf OpenPorchSF, EnclosedPorch and ScreenPorch"
      ],
      "metadata": {
        "id": "Y07AJCf6kguR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering\n",
        "def drop_features(df):\n",
        "    #Unusable features\n",
        "    df.drop(not_usable, axis=1, inplace=True)\n",
        "\n",
        "      \n",
        "    # Features that are highly related\n",
        "    '''\n",
        "    - GarageYrBlt and YearBuilt\n",
        "    - TotRmsAbvGrd and GrLivArea\n",
        "    - 1stFlrSF and TotalBsmtSF\n",
        "    - GarageArea and GarageCars\n",
        "    We remove one of every pair to prevent the problem of multicollinearity. Multicollinearity is when 2 or more\n",
        "    independent variables are highly correlated with another. This negatively affects the model's ability to identify\n",
        "    the most important features'''\n",
        "    df.drop(['GarageYrBlt','TotRmsAbvGrd','1stFlrSF','GarageCars'], axis=1, inplace=True)\n",
        "\n",
        "    # These feature have no linear relation with SalePrice at all\n",
        "    df.drop(['MoSold','YrSold'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    #Features that have mostly just one value\n",
        "    # If a feature has 96% or more of only one value, we drop it\n",
        "    all_features = list(df.columns[1:])\n",
        "    overfit_cat = []\n",
        "    for i in all_features:\n",
        "        counts = df[i].value_counts()\n",
        "        zeros = counts.iloc[0]\n",
        "        if zeros / len(df) * 100 > 96:\n",
        "            overfit_cat.append(i)\n",
        "\n",
        "    overfit_cat = list(overfit_cat)\n",
        "    df.drop(overfit_cat, axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_outliers(df):\n",
        "    df.drop(df[df['LotFrontage'] > 200].index, inplace=True)\n",
        "    df.drop(df[df['LotArea'] > 100000].index, inplace=True)\n",
        "    df.drop(df[df['BsmtFinSF1'] > 4000].index, inplace=True)\n",
        "    df.drop(df[df['TotalBsmtSF'] > 5000].index, inplace=True)\n",
        "    df.drop(df[df['GrLivArea'] > 4000].index, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def add_features(df):\n",
        "\n",
        "    #Sum of features\n",
        "    df['TotalLot'] = df['LotFrontage'] + df['LotArea']\n",
        "    df['TotalBsmtFin'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n",
        "    df['TotalBath'] = df['FullBath'] + df['HalfBath']\n",
        "    df['TotalPorch'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch']\n",
        "\n",
        "    #Binary columns for features that indicate presence\n",
        "    colum = ['MasVnrArea','TotalBsmtFin','TotalBsmtSF','2ndFlrSF','WoodDeckSF','TotalPorch']\n",
        "\n",
        "    for col in colum:\n",
        "        col_name = col+'_bin'\n",
        "        df[col_name] = df[col].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "    #The following additional features cause the model to overfit, so maybe we should only apply it on specific features\n",
        "    #Applying it on numeric features only makes the model weaker\n",
        "\n",
        "    #Cross product of all categories\n",
        "    allcat = list(df.columns[1:])\n",
        "    '''\n",
        "    for i in range(len(allcat)):\n",
        "        cat_a = allcat[i]\n",
        "        for j in range(i + 1, len(allcat)):\n",
        "            cat_b = allcat[j]\n",
        "            col_name = f'{cat_a} * {cat_b}'\n",
        "            df[col_name] = df[df.columns[i]] * df[df.columns[j]]\n",
        "    '''\n",
        "    #Square of each category\n",
        "    '''\n",
        "    for i in range(len(allcat)):\n",
        "        cat = allcat[i]\n",
        "        col_name = f'{cat}^2'\n",
        "        df[col_name] = df[df.columns[i]] ** 2\n",
        "    '''\n",
        "\n",
        "    #Third power of each category\n",
        "    '''\n",
        "    for i in range(len()):\n",
        "        cat = allcat[i]\n",
        "        col_name = f'{cat}^3'\n",
        "        df[col_name] = df[df.columns[i]] ** 3\n",
        "    '''\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "08wTNGnCkXSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apart from these steps, we can also transform the numerical features by Box Cox and YeoJohnson. These will be datasets bc_df and yj_df respectively"
      ],
      "metadata": {
        "id": "KBw8DzsemqZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box cox transform all numericals except saleprice, \n",
        "# as it is almost exactly a log-normal dist, so it gets log-transformed\n",
        "bc_df = ppr_df.copy()\n",
        "skewlist = []\n",
        "for i in bc_df[num_col]:\n",
        "    if abs(bc_df[i].skew()) > 0.5:\n",
        "        skewlist.append(i)\n",
        "\n",
        "for v in bc_df[skewlist]:\n",
        "    if v != 'SalePrice':\n",
        "        lambda_list = []\n",
        "        tmp = boxcox1p(bc_df[v], 0.25)\n",
        "        bc_df[v] = tmp\n",
        "    if v == 'SalePrice':\n",
        "        tmp = np.log1p(bc_df[v])\n",
        "        bc_df[v] = tmp\n",
        "\n",
        "# Find all columns that are skewed and yeo-johnson transform all of them:\n",
        "skewlist = []\n",
        "for i in df[num_col]:\n",
        "    if abs(df[i].skew()) > 0.5:\n",
        "        skewlist.append(i)\n",
        "yj_df = pd.DataFrame(power_transform(df[skewlist], method='yeo-johnson'), columns=skewlist)"
      ],
      "metadata": {
        "id": "q1Nxf3cJleEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now what we have are 2 different transformed datasets and 3 functions to apply manual feature engineering, however we do not know what works best yet. So let's make a combination of all of them with all the forms of dataset (including ppr_df). This will leave us with 2x8 models of which we later on will have to determine which one is the best for the model we want to use. Since Yeo Johnson already has reduced features, we will not apply any of the drop features, add features or remove outliers on this dataset \n",
        "\n",
        ">ppr_df: basis preprocessed dataset\n",
        "\n",
        "*   ppr_dr_df: ppr with drop features\n",
        "*   ppr_ro_df: ppr with remove outliers\n",
        "*   ppr_af_df: ppr with add featuers\n",
        "*   ppr_dr_ro_df: ppr with drop features and remove outliers\n",
        "*   ppr_df_af_df: ppr with drop features and add features\n",
        "*   ppr_ro_af_df: ppr with remove outliers and add features\n",
        "*   ppr_dr_ro_df: ppr with drop features, remove outliers and add features\n",
        "\n",
        "\n",
        ">bc_df: basis preprocessed dataset with Box Cox transformation\n",
        "\n",
        "*   bc_dr_df: bc with drop features\n",
        "*   bc_ro_df: bc with remove outliers\n",
        "*   bc_af_df: bc with add featuers\n",
        "*   bc_dr_ro_df: bc with drop features and remove outliers\n",
        "*   bc_df_af_df: bc with drop features and add features\n",
        "*   bc_ro_af_df: bc with remove outliers and add features\n",
        "*   bc_dr_ro_df: bc with drop features, remove outliers and add features\n",
        "\n",
        ">yj_df: basis preprocessed dataset with Yeo Johnson transformation"
      ],
      "metadata": {
        "id": "vsPBK3chn3Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessed\n",
        "\n",
        "#Drop Features\n",
        "ppr_dr_df = ppr_df.copy()\n",
        "ppr_dr_df = drop_features(ppr_dr_df)\n",
        "#Remove Outliers\n",
        "ppr_ro_df = ppr_df.copy()\n",
        "ppr_ro_df = remove_outliers(ppr_df)\n",
        "#Add Features\n",
        "ppr_af_df = ppr_df.copy()\n",
        "ppr_af_df = add_features(ppr_af_df)\n",
        "#Drop Features + Remove Outliers\n",
        "ppr_dr_ro_df = ppr_dr_df.copy()\n",
        "ppr_dr_ro_df = remove_outliers(ppr_ro_df)\n",
        "#Drop Features + Add Features\n",
        "ppr_dr_af_df = ppr_dr_df.copy()\n",
        "ppr_dr_af_df = add_features(ppr_dr_af_df)\n",
        "#Remove Outliers + Add Features\n",
        "ppr_ro_af_df = ppr_df.copy()\n",
        "ppr_ro_af_df = remove_outliers(ppr_ro_af_df)\n",
        "ppr_ro_af_df = add_features(ppr_ro_af_df)\n",
        "#Drop Features + Remove Outliers + Add Features\n",
        "ppr_dr_ro_af_df = ppr_dr_df.copy()\n",
        "ppr_dr_ro_af_df = remove_outliers(ppr_dr_ro_af_df)\n",
        "ppr_dr_ro_af_df = add_features(ppr_dr_ro_af_df)\n",
        "\n",
        "\n",
        "#Box Cox DF\n",
        "\n",
        "#Drop Features\n",
        "bc_dr_df = bc_df.copy()\n",
        "bc_dr_df = drop_features(bc_dr_df)\n",
        "#Remove Outliers\n",
        "bc_ro_df = bc_df.copy()\n",
        "bc_ro_df = remove_outliers(bc_ro_df)\n",
        "#Add Features\n",
        "bc_af_df = bc_df.copy()\n",
        "bc_af_df = add_features(bc_af_df)\n",
        "#Drop Features + Remove Outliers\n",
        "bc_dr_ro_df = bc_dr_df.copy()\n",
        "bc_dr_ro_df = remove_outliers(bc_dr_ro_df)\n",
        "#Drop Features + Add Features\n",
        "bc_dr_af_df = bc_dr_df.copy()\n",
        "bc_dr_af_df = add_features(bc_dr_af_df)\n",
        "#Remove Outliers + Add Features\n",
        "bc_ro_af_df = bc_df.copy()\n",
        "bc_ro_af_df = remove_outliers(bc_ro_af_df)\n",
        "bc_ro_af_df = add_features(bc_ro_af_df)\n",
        "#Drop Features + Remove Outliers + Add Features\n",
        "bc_dr_ro_af_df = bc_dr_df.copy()\n",
        "bc_dr_ro_af_df = remove_outliers(bc_dr_ro_af_df)\n",
        "bc_dr_ro_af_df = add_features(bc_dr_ro_af_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "cZrjLBXbo6oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection\n",
        "Recursive Feature Elimination \n",
        "\n",
        "An ‘automated’ alternative to feature engineering: Feature selection. By using L1 regularization recursively, features with little effect on the predictive power are regularized out, i.e. assigned a weight of 0. \n",
        "\n",
        "For this we are using a different preprocessed dataset, which uses the preproccesing variant without the impute function.\n",
        "\n",
        "This will be the feature selection dataframe fs_df"
      ],
      "metadata": {
        "id": "09YIe0EOz4Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  split(df, val_frac=0.2, seed=1):\n",
        "    # Validation set is a sample of val_frac size. Deafult is 0.2, or 20%. \n",
        "    # Seed is either 0 for no seed, 1 for default seed, or a real number as seed.\n",
        "    if seed == 0:\n",
        "        val = df.sample(frac=val_frac)\n",
        "    if seed == 1: \n",
        "        val = df.sample(frac=val_frac, random_state=200)\n",
        "    else:\n",
        "        val = df.sample(frac=val_frac, random_state=seed)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "    return train, val"
      ],
      "metadata": {
        "id": "yQOKG2MBj6Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(df):\n",
        "  train, val = split(df)\n",
        "  selector = RFECV(Lasso(normalize=True), step=1, n_jobs=6)\n",
        "  X = train.drop(['SalePrice'], axis=1)\n",
        "  # Ignore deprecation warning. The pipeline it suggests didn't immediately work\n",
        "  # and I didn't feel like spending time one that when it still works even though it's deprecated.\n",
        "  selector = selector.fit(X, train.SalePrice)\n",
        "  # Number of features left after selecting best features\n",
        "  len(selector.get_feature_names_out())\n",
        "  # list of all the features that have been selected\n",
        "  selected = selector.get_feature_names_out().tolist()\n",
        "  selected.extend([\"SalePrice\"])\n",
        "  # list of all features\n",
        "  features = train.columns\n",
        "  # list of features that have been removed\n",
        "  removed = [i for i in features if i not in selected]\n",
        "  # fs_df is feature selected data frame\n",
        "  fs_df = fs_init_df.drop(removed, axis=1)\n",
        "  return fs_df"
      ],
      "metadata": {
        "id": "wOqR0W10tASk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get new dataframe\n",
        "fs_init_df = init_df.copy()\n",
        "# Preprocess, fill NaN, fill also LotFrontage (no imputing)\n",
        "fs_init_df = preprocess(fs_init_df, remlf=0)"
      ],
      "metadata": {
        "id": "V6lUmQwaV1-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs_df = feature_selection(fs_init_df)"
      ],
      "metadata": {
        "id": "lZ9advxlzRmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you need a dataframe of just the selected features for your code:"
      ],
      "metadata": {
        "id": "VMxhvNVx8Y_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backup of the 'Removed' list:\n",
        "_removed_ = ['MSSubClass_20','MSSubClass_45','MSSubClass_50','MSSubClass_90','MSZoning_RL',\n",
        "'Street_Pave','Alley_None','Alley_Pave','LandContour_Lvl','LotConfig_Inside',\n",
        "'Neighborhood_Gilbert','Neighborhood_NAmes','Neighborhood_OldTown',\n",
        "'Condition1_Artery','Condition2_Feedr','BldgType_Duplex','RoofStyle_Gable',\n",
        "'RoofMatl_ClyTile', 'RoofMatl_CompShg', 'RoofMatl_Metal', 'Exterior1st_CBlock',\n",
        "'Exterior1st_HdBoard', 'Exterior2nd_AsbShng', 'Exterior2nd_MetalSd', 'Exterior2nd_Other',\n",
        "'Exterior2nd_Plywood', 'BsmtFinType1_BLQ', 'BsmtFinType2_LwQ','Electrical_FuseF',\n",
        "'FireplaceQu_Gd','PavedDrive_Y','Fence_MnWw', 'Fence_None','SaleCondition_Normal',\n",
        "'SaleCondition_Partial','MasVnrType_None','Foundation_PConc','Heating_Grav',\n",
        "'CentralAir_Y','GarageType_BuiltIn','SaleType_COD','MiscFeature_None','GarageCond']\n",
        "\n",
        "df = init_df.copy()\n",
        "df = preprocess(df, remlf=0)\n",
        "fs_df = df.drop(_removed_, axis=1)"
      ],
      "metadata": {
        "id": "z8ed8raP8Wj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction\n",
        "\n",
        "With Dimensionality Reduction we aim to reduce the amount of features we have by creating new features based on the correlation between the existing features. This is mainly done by PCA (Principal Component Analysis) for numeric features, MCA (Multiple Correspondence Analysis) for categoric features and FAMD (Factor Analysis of Mixed Data). \n",
        "\n",
        "In order to make use of these three forms of dimensionality reduction, let's create functions which allow us to supply it with a dataset and a model which we want to run it."
      ],
      "metadata": {
        "id": "-2vqV5l-Z-i9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Principal Component Analysis (PCA)**\n",
        "\n",
        "For applying PCA, we will use the Sklearn PCA functionality and allow for 3 different variable\n",
        "\n",
        "1. Models, as while this method is still a way of preprocessing the data, Dimensionality reduction is the last step we will apply to our dataset, thus we can build in a model to test it with and get a result. Futhermore, using a model now also allows us to experiment a bit to find the correct number of features, as explained in 3.\n",
        "\n",
        "2. The dataset, here we can enter which dataset we want to apply PCA to.  \n",
        "\n",
        "3. The number of features kept; basically the less features we have, the less accurate the model becomes, but it also reduces the variance, which makes it less prone to overfitting. The goal here is to find the best amount of features. This will be done by using the amount of features avaiable in the dataset and using n_components in the SKlearn PCA function to reduce them by 1 per step. The accuracy results of the validation will be plotted to find the best accuracy."
      ],
      "metadata": {
        "id": "YXcVIhj7eQcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin, let's go over the function that will make the magic happen: pca_evaluation.\n",
        "\n",
        "The goal of this function is to perform pca with a different hyperparameter (n_components) and then store the result in a list as (model score, n_components) such that we can evaluate it. \n",
        "\n",
        "To go over this step by step, we want to create a dataset of the features and the target. So we separate out SalePrice into y and features into X, which we both split up into an 80% training set and 20% validation set by random_state key 200.\n",
        "\n",
        "First off, we want to do a baseline test, how well does our model perform without PCA. This will be score equal to the number of features the dataset has  and will be stored in pca_scores. Features is an input variable here, as each of our datasets has a different amount of features due to pre-processing\n",
        "\n",
        "Then we introduce PCA. Sklearn uses n_components as a parameter for its PCA function, which determines how many features the PCA should produce. Since we want to reduce dimensionality, we're taking steps of -1 from the number of features in the dataset to 0. \n",
        "\n",
        "Each model score is stored in pca_scores, which are represented by a scatterplot for easy viewing and printed for direct readout. This direct readout is limited in range between 0 and 1, as that's the only relevant range. Furthermore, the best score and number of components are printed."
      ],
      "metadata": {
        "id": "6I6ZFzNhaB2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_evaluation(model, df, features):\n",
        "  x_col = df.drop(['Id', 'SalePrice'], axis=1)\n",
        "  X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "  y = df['SalePrice'].values\n",
        "\n",
        "  pca_scores = [] \n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=200)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  pca_scores.append((model.score(X_test, y_test), features))\n",
        "  \n",
        "  for i in range((features-1), 0, -1):\n",
        "    pca = PCA(n_components = i)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=200)\n",
        "    \n",
        "    model.fit(X_train_pca, y_train)\n",
        "    pca_scores.append((model.score(X_test_pca, y_test),i))\n",
        "\n",
        "  x_coord= []\n",
        "  y_coord= [] \n",
        "  for i in range(0,len(pca_scores),1):\n",
        "    x_coord.append(pca_scores[i][1])\n",
        "    y_coord.append(pca_scores[i][0])\n",
        "  plt.scatter(x_coord,y_coord)\n",
        "  plt.ylim(0, 1)\n",
        "  print(pca_scores)\n",
        "  return(max(pca_scores))"
      ],
      "metadata": {
        "id": "YYTlz3rRQcYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA  function\n",
        "\n",
        "While the pca_evaluation function can be used to find the optimal number of features, the pca_test function can be used to run a model with PCA"
      ],
      "metadata": {
        "id": "WM8DgUWmAWSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyparsing.exceptions import ParseSyntaxException\n",
        "def pca(model, df, features):\n",
        "    x_col = df.drop(['Id', 'SalePrice'], axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = df['SalePrice'].values\n",
        "\n",
        "\n",
        "    pca = PCA(n_components = features)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=200)\n",
        "\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    print('Training Results:')\n",
        "    try:\n",
        "        print(f'Mean squared log error loss on training: {sklearn.metrics.mean_squared_log_error(model.predict(X_train_pca), y_train)}')\n",
        "    except:\n",
        "        ParseSyntaxException\n",
        "    print(model.score(X_train_pca, y_train))\n",
        "    print(\"Validation Results\")\n",
        "    print(model.score(X_test_pca, y_test))\n",
        "    try:\n",
        "        print(f'Mean squared log error loss on validation: {sklearn.metrics.mean_squared_log_error(model.predict(X_test_pca), y_test)}')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    plt.scatter(model.predict(X_train_pca), y_train, marker = \"s\",  c = \"blue\", label = \"Training\")\n",
        "    plt.scatter(model.predict(X_test_pca), y_test, marker = \"s\",  c = \"green\", label = \"Validation\")\n",
        "    plt.plot([10, 13.5], [10, 13.5], color = 'red')\n",
        "    plt.title(\"Linear regression\")\n",
        "    plt.xlabel(\"Predicted values\")\n",
        "    plt.ylabel(\"Real values\")\n",
        "    plt.legend(loc = \"upper left\")\n",
        "    print()\n",
        "    print(\"Standard error:{:>10} {}\".format(\" \", std_err(model.predict(X_test_pca), y_test)))\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "TtYy948EAVyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  MCA for nominal columns\n",
        "\n",
        "MCA is used for the nominal features. In order to be able to separate these from the numerical features, we introduce a separate_num_nom function which separates the nominal binary features from the numerical features.\n",
        "\n",
        "Then we have a MCA function which returns an MCA processed dataset "
      ],
      "metadata": {
        "id": "EhqCrUIx_PE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_binary(series, allow_na=False):\n",
        "    if allow_na:\n",
        "        series.dropna(inplace=True)\n",
        "    return sorted(series.unique()) == [0, 1]\n",
        "\n",
        "def separate_num_nom(df):\n",
        "  num = []\n",
        "  nom = []\n",
        "  for col in df.columns:\n",
        "      if is_binary(df[col]) == False:\n",
        "          num.append(col)\n",
        "      else:\n",
        "          nom.append(col)\n",
        "  return num, nom"
      ],
      "metadata": {
        "id": "FFOFosx-Ut1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  mca(df, n=2):\n",
        "    mca = prince.MCA(\n",
        "        n_components=n,\n",
        "        n_iter=10,\n",
        "        copy=True,\n",
        "        check_input=True,\n",
        "        engine='auto',\n",
        "        random_state=42\n",
        "        )\n",
        "    num, nom = separate_num_nom(df)\n",
        "    mca_df = mca.fit_transform(df[nom])\n",
        "    mca_df['SalePrice'] = df['SalePrice']\n",
        "    return mca_df"
      ],
      "metadata": {
        "id": "YPw1kDc3ZDGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_df = mca(ppr_df)"
      ],
      "metadata": {
        "id": "YJI7s-9VN_7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying FAMD dimensionality reduction to all columns"
      ],
      "metadata": {
        "id": "ud67XtPPAJCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Famd(model, df): \n",
        "    famd = prince.FAMD(\n",
        "        n_components=10,\n",
        "        n_iter=3,\n",
        "        copy=True,\n",
        "        check_input=True,\n",
        "        engine='auto',\n",
        "        random_state=42\n",
        "    )\n",
        "    famd_df = famd.fit_transform(df.drop(['SalePrice'], axis=1))\n",
        "\n",
        "    famd_df['SalePrice'] = df['SalePrice']\n",
        "\n",
        "    df = famd_df\n",
        "\n",
        "    drop, target = ['SalePrice'], ['SalePrice']\n",
        "\n",
        "\n",
        "    # Validation set is a sample of 20%. Seed is used to get consistent results while testing\n",
        "    val = df.sample(frac=0.2,random_state=200)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "\n",
        "    x_col = train.drop(drop, axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = train[target].values\n",
        "\n",
        "    reg = model.fit(X, y)\n",
        "\n",
        "    print(\"Training results\")\n",
        "    print(reg.score(X, y))\n",
        "    try:\n",
        "        print(f'Mean squared log error loss on training: {sklearn.metrics.mean_squared_log_error(reg.predict(X), y)}')\n",
        "    except:\n",
        "        pass\n",
        "    valx_col = val.drop(drop, axis=1)\n",
        "    valx = valx_col.values.reshape(-1, len(valx_col.columns))\n",
        "    valy = val[target].values\n",
        "\n",
        "    print()\n",
        "    print(\"Validation results\")\n",
        "    print(reg.score(valx, valy))\n",
        "    try:\n",
        "        print(f'Mean squared log error loss on validation: {sklearn.metrics.mean_squared_log_error(reg.predict(valx), valy)}')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    plt.scatter(reg.predict(X), y, marker = \"s\",  c = \"blue\", label = \"Training\")\n",
        "    plt.scatter(reg.predict(valx), valy, marker = \"s\",  c = \"green\", label = \"Validation\")\n",
        "    plt.plot([10, 13.5], [10, 13.5], color = 'red')\n",
        "    plt.title(\"Linear regression\")\n",
        "    plt.xlabel(\"Predicted values\")\n",
        "    plt.ylabel(\"Real values\")\n",
        "    plt.legend(loc = \"upper left\")\n",
        "    print()\n",
        "    print(\"Standard error:{:>10} {}\".format(\" \", std_err(y_true, y_pred)))\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "8zA4bzJ7AJJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "famd_df = fillnan(df, remlf=0)"
      ],
      "metadata": {
        "id": "L0Ib4tGOadNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n",
        "Now that we have all our preprocessing functions setup, let's take a look at the models we are going to work with.\n",
        "> LinearRegression\n",
        "\n",
        ">Standard linear model with no regularization. Used to test feature engineering, selection and dimensionality reduction, as it ensures features selected/created aren’t “regularized out”\n",
        "\n",
        "> RidgeCV\n",
        "\n",
        ">Cross-validated L2-regularized regression model. Deals partly with collinearity due to L2 weights minimizing impacts of multicollinear or weakly correlated variables\n",
        "\n",
        ">LassoCV\n",
        "\n",
        ">Cross-validated L1-regularized regression model. Deals (in theory) entirely with collinearity and poor correlations, by effectively selecting best features to use in the correlation– Bad features are regularized out by giving a weight of 0.\n",
        "\n",
        ">Adaboost\n",
        "\n",
        ">Ensemble model which trains a set of models in sequence and improves on them by learning the mistakes it has made.\n",
        "\n",
        ">XGBoost\n",
        "\n",
        ">Similar to but more flexible then Adaboost.\n",
        "\n",
        "To run these models, let's create a regressor function that does the train-test split of the data for us and give us a score of the performance of the model with the provided dataset\n"
      ],
      "metadata": {
        "id": "1b9Ob75TuRaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regressor(model, df, drop=['SalePrice'], target=['SalePrice']):\n",
        "    # Validation set is a sample of 20%. Seed is used to get consistent results while testing\n",
        "    val = df.sample(frac=0.2,random_state=200)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "\n",
        "    x_col = train.drop(drop, axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = ravel(train[target].values)\n",
        "\n",
        "    reg = model.fit(X, y)\n",
        "\n",
        "    valx_col = val.drop(drop, axis=1)\n",
        "    valx = valx_col.values.reshape(-1, len(valx_col.columns))\n",
        "    valy = ravel(val[target].values)\n",
        "\n",
        "    print(\"Training results\")\n",
        "    print(reg.score(X, y))\n",
        "    try:\n",
        "      print(f'Mean squared log error loss on training: {sklearn.metrics.mean_squared_log_error(reg.predict(X), y)}')\n",
        "    except:\n",
        "        pass\n",
        "    print(\"Validation results\")\n",
        "    print(reg.score(valx, valy))\n",
        "    try:\n",
        "      print(f'Mean squared log error loss on validation: {sklearn.metrics.mean_squared_log_error(reg.predict(valx), valy)}')\n",
        "    except:\n",
        "        pass\n",
        "    plt.scatter(reg.predict(X), y, marker = \"s\",  c = \"blue\", label = \"Training\")\n",
        "    plt.scatter(reg.predict(valx), valy, marker = \"s\",  c = \"green\", label = \"Validation\")\n",
        "    plt.plot([10, 13.5], [10, 13.5], color = 'red')\n",
        "    plt.title(\"Linear regression\")\n",
        "    plt.xlabel(\"Predicted values\")\n",
        "    plt.ylabel(\"Real values\")\n",
        "    plt.legend(loc = \"upper left\")\n",
        "    print()\n",
        "    print(\"Standard error:{:>10} {}\".format(\" \", std_err(valy, reg.predict(valx))))\n",
        "    print()"
      ],
      "metadata": {
        "id": "umZLiLLFvpQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  std_err(y_true, y_pred):   \n",
        "    error = []\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        # Shift data to positive values if negative. \n",
        "        # Log error is not affected because both values are moved.\n",
        "        if true < 0:\n",
        "            true = abs(true)\n",
        "            diff = true * 2\n",
        "            pred = pred + diff\n",
        "        if pred < 0:\n",
        "            pred = abs(pred)\n",
        "            diff = pred * 2\n",
        "            true = true + diff\n",
        "\n",
        "        error.append(sklearn.metrics.mean_squared_log_error([true], [pred]))\n",
        "\n",
        "    std_err = scipy.stats.bootstrap((error,), np.mean, method='basic').standard_error   \n",
        "    return std_err"
      ],
      "metadata": {
        "id": "8RVHU_g_SPQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  getarr(df, drop=['SalePrice'], target=['SalePrice']):\n",
        "    # gets array of X and y from dataframe to feed model\n",
        "    x_col = train.drop(drop, axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = ravel(train[target].values)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "KRfCYaj7lgXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal dimensionality reduction values\n",
        "\n",
        "So now we have a regressor function and we have defined our models, we need to finalize our models. This is important because we want to have 4 dataframes that we can test with; 1 for preprocessing, 1 for feature engineering, 1 for feature selection, 1 for Dimensionality reduction. \n",
        "\n",
        "However as it stands now, these are the datasets we have\n",
        ">Preprocessing: ppr_df\n",
        "\n",
        ">Feature Engineering: 16 different datasets\n",
        "\n",
        ">Feature Selection: fs_df\n",
        "\n",
        ">Dimensionality Reduction: datasets first need to be run through models to determine the best number of features for PCA and then bet compared to FAMD and MCA to see which of the 3 is best. \n",
        "\n",
        "So let's finalize this right now.\n"
      ],
      "metadata": {
        "id": "sFPpNjx1MTk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**\n",
        "\n",
        "For feature engineering, we have 16 different datasets: the adjusted ppr_df to bc_df and yj_df and then the drop_features, add_features, remove_outliers variants. \n",
        "\n",
        "During testing it has turned out that the yj_df only returns errors for all the models and the bc_dfs return errors for AdaBoost, so we're not using those. \n",
        "This leaves us with running all the datasets through the models and then picking the best dataset for each model. We're recording both testing results and validation results, but the final model will be the best val model."
      ],
      "metadata": {
        "id": "8HAF7yBncQL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_reg(model, df, drop=['SalePrice'], target=['SalePrice']):\n",
        "    # Validation set is a sample of 20%. Seed is used to get consistent results while testing\n",
        "    val = df.sample(frac=0.2,random_state=200)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "\n",
        "    x_col = train.drop(drop, axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = ravel(train[target].values)\n",
        "\n",
        "    reg = model.fit(X, y)\n",
        "\n",
        "    valx_col = val.drop(drop, axis=1)\n",
        "    valx = valx_col.values.reshape(-1, len(valx_col.columns))\n",
        "    valy = ravel(val[target].values)\n",
        "\n",
        "    \n",
        "    train_res = reg.score(X, y) \n",
        "    val_res = reg.score(valx, valy)\n",
        "    \n",
        "    return(train_res, val_res)\n",
        "    "
      ],
      "metadata": {
        "id": "kAPYm1tuQAMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Linear_Regression_train = []\n",
        "Linear_Regression_val = []\n",
        "RidgeCV_train = []\n",
        "RidgeCV_val = []\n",
        "LassoCV_train = []\n",
        "LassoCV_val = []\n",
        "Adaboost_train = []\n",
        "Adaboost_val = []\n",
        "XGboost_train = []\n",
        "XGboost_val = []\n",
        "\n",
        "datasets = [ ppr_dr_df, ppr_ro_df, ppr_af_df, ppr_dr_ro_df, ppr_dr_af_df, ppr_ro_af_df, ppr_dr_ro_af_df, bc_df, bc_dr_df, bc_ro_df,bc_af_df, bc_dr_ro_df, bc_dr_af_df, bc_ro_af_df, bc_dr_ro_af_df]\n",
        "dataset_name = ['ppr_dr_df', 'ppr_ro_df', 'ppr_af_df', 'ppr_dr_ro_df', 'ppr_dr_af_df', 'ppr_ro_af_df', 'ppr_dr_ro_af_df', 'bc_df', 'bc_dr_df', 'bc_ro_df','bc_af_df', 'bc_dr_ro_df', 'bc_dr_af_df', 'bc_ro_af_df', 'bc_dr_ro_af_df']\n",
        "models = [LinearRegression(), RidgeCV(), LassoCV(), AdaBoostRegressor(n_estimators= 100, learning_rate = 1), XGBRegressor(booster='gbtree', objective='reg:squarederror')]\n",
        "model_count = 0\n",
        "dataset_count = 0 \n",
        "for model in models:\n",
        "  model_count += 1 \n",
        "  if model_count == 4:\n",
        "      del datasets[7:15]\n",
        "  for dataset in datasets: \n",
        "    name = dataset_name[dataset_count]\n",
        "    dataset_count += 1\n",
        "    train_res, val_res = eval_reg(model, dataset)\n",
        "    if model_count == 1:\n",
        "      Linear_Regression_train.append((train_res, name))\n",
        "      Linear_Regression_val.append((val_res, name))\n",
        "    if model_count == 2:\n",
        "      RidgeCV_train.append((train_res, name))\n",
        "      RidgeCV_val.append((val_res, name))\n",
        "    if model_count == 3:\n",
        "      LassoCV_train.append((train_res, name))\n",
        "      LassoCV_val.append((val_res,name))\n",
        "    if model_count == 4:\n",
        "      Adaboost_train.append((train_res, name))\n",
        "      Adaboost_val.append((val_res, name))\n",
        "    if model_count == 5:\n",
        "      XGboost_train.append((train_res, name))\n",
        "      XGboost_val.append((val_res, name))\n",
        "  dataset_count = 0\n",
        "\n",
        "print('Linear Regression:')\n",
        "print(max(Linear_Regression_train))\n",
        "print(max(Linear_Regression_val))\n",
        "print('RidgeCV:')\n",
        "print(max(RidgeCV_train))\n",
        "print(max(RidgeCV_val))\n",
        "print('LassoCV:')\n",
        "print(max(LassoCV_train))\n",
        "print(max(LassoCV_val))\n",
        "print('AdaBoost:')\n",
        "print(max(Adaboost_train))\n",
        "print(max(Adaboost_val))\n",
        "print('XGBoost:')\n",
        "print(max(XGboost_train))\n",
        "print(max(XGboost_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "FPa5b58sOius"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see this leaves us with the following\n",
        "> Preprocessing: ppr_df\n",
        "\n",
        "> Feature Engineering\n",
        ">*   Linear Regression: ppr_dr_ro_af_df\n",
        ">*   RidgeCV: ppr_ro_af_df\n",
        ">*   LassoCV: ppr_dr_ro_af_df\n",
        ">*   AdaBoost: ppr_ro_df\n",
        ">*   XGBoost : ppr_ro_af_df\n",
        "\n",
        "> Feature Selection: fs_df\n",
        "\n",
        "So now let's take a look at Dimensionality Reduction\n",
        "\n"
      ],
      "metadata": {
        "id": "woUj2Nhbc_HI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimensionality Reduction**\n",
        "\n",
        "For Dimensionality Reduction we have 3 methods of Dimensionality reduction: PCA, MCA and FAMD.\n",
        "\n",
        "To choose which one we want to use for each model, let's run them and take the best performer.\n",
        "\n",
        "We start with PCA to find the optimal amount of features per each model. \n"
      ],
      "metadata": {
        "id": "fHrYCVOFdeKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [LinearRegression(), RidgeCV(), LassoCV(), AdaBoostRegressor(n_estimators= 100, learning_rate = 1), XGBRegressor(booster='gbtree', objective='reg:squarederror')]\n",
        "model_count = 0\n",
        "for model in models:\n",
        "  max_score = pca_evaluation(model, ppr_df, 262)\n",
        "  if model_count == 0:\n",
        "    print('Linear Regression: ', max_score)\n",
        "  if model_count == 1:\n",
        "    print('RidgeCV: ', max_score)  \n",
        "  if model_count == 2:\n",
        "    print('LassoCV: ', max_score) \n",
        "  if model_count == 3:\n",
        "    print('AdaBoost: ', max_score) \n",
        "  if model_count == 4:\n",
        "    print('XGBoost: ', max_score)\n",
        "  model_count += 1"
      ],
      "metadata": {
        "id": "tUOTCmfNgYC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't want to run this (as Adaboost can make this take over 20 minutes), here are the results:\n",
        "\n",
        "*   Linear Regression: 134 \n",
        "*   RidgeCV: 134\n",
        "*   LassoCV: 262\n",
        "*   AdaBoost: 262\n",
        "*   XGBoost: 262\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "crxP38sMklKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "dTUr7ifylJ8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LinearRegression(), ppr_df, 134)"
      ],
      "metadata": {
        "id": "8JsAfhnBloF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), mca_df)"
      ],
      "metadata": {
        "id": "n7nHvsZ7lVMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LinearRegression(), famd_df)"
      ],
      "metadata": {
        "id": "10ZG-U-RlG23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see PCA has the best results for Linear Regression with 134 features"
      ],
      "metadata": {
        "id": "rqIL7T1nrOol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RidgeCV**"
      ],
      "metadata": {
        "id": "QhL1PN3Dl3G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(RidgeCV(), ppr_df, 134)"
      ],
      "metadata": {
        "id": "VJIdJ8COltDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(RidgeCV(), mca_df)"
      ],
      "metadata": {
        "id": "mVbwA9cYltDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(RidgeCV(), famd_df)"
      ],
      "metadata": {
        "id": "C1Kx1NpqltDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same Results as with Linear Regression: PCA with  134 features is best"
      ],
      "metadata": {
        "id": "9k7rAB6tredT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LassoCV**"
      ],
      "metadata": {
        "id": "qBeZTGLCl8SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LassoCV(), ppr_df, 262)"
      ],
      "metadata": {
        "id": "UETft3w5l6ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LassoCV(), mca_df)"
      ],
      "metadata": {
        "id": "FS3K9Acel6ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LassoCV(), famd_df)"
      ],
      "metadata": {
        "id": "lmTFz_spl6ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that LassoCV has best validation results with PCA and 262 features"
      ],
      "metadata": {
        "id": "nkxJl8r1rzV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdaBoost**"
      ],
      "metadata": {
        "id": "x3kPGPzAmFbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_df, 262)"
      ],
      "metadata": {
        "id": "hRKISGMFmE26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), mca_df)"
      ],
      "metadata": {
        "id": "_wbyaQ3MmE27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), famd_df)"
      ],
      "metadata": {
        "id": "K3nbVJpzmE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For AdaBoost we find that MCA has the best validation results"
      ],
      "metadata": {
        "id": "vaGRLMT7Ramp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**"
      ],
      "metadata": {
        "id": "Me0GBffU19cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_df, 262)"
      ],
      "metadata": {
        "id": "x6ttfJZU19ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), mca_df)"
      ],
      "metadata": {
        "id": "qSHnxHT019ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(XGBRegressor(booster='gbtree', objective='reg:squarederror'), famd_df)"
      ],
      "metadata": {
        "id": "ug7evjSW19ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see PCA works the best for XGBoost with 262 features"
      ],
      "metadata": {
        "id": "zWABnsSNEZj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, so now we have the following datasets\n",
        "> Preprocessing: ppr_df\n",
        "\n",
        "> Feature Engineering\n",
        ">*   Linear Regression: ppr_dr_ro_af_df\n",
        ">*   RidgeCV: ppr_ro_af_df\n",
        ">*   LassoCV: ppr_dr_ro_af_df\n",
        ">*   AdaBoost: ppr_ro_df\n",
        ">*   XGBoost : ppr_ro_af_df\n",
        "\n",
        "> Feature Selection: fs_df\n",
        "\n",
        "> Dimensionality Reduction\n",
        ">*   Linear Regression: PCA, 134\n",
        ">*   RidgeCV: PCA, 134\n",
        ">*   LassoCV: PCA, 262\n",
        ">*   AdaBoost: MCA\n",
        ">*   XGBoost: PCA, 262\n",
        "\n",
        "Now what we need to do is to create our 8 datasets per model which look as follows\n",
        "\n",
        "* Dataset 1: Preproccessed only (ppr_df)\n",
        "\n",
        "* Dataset 2: Preprocessed + Feature engineering (depending on model)\n",
        "\n",
        "* Dataset 3: Preprocessed + Feature Selection (fs_df) \n",
        "\n",
        "* Dataset 4: Preprocessed + Dimensionality Reduction (depending on model)\n",
        "\n",
        "* Dataset 5: Preprocessed + Feature Engineering + Selection (using feature selection function on FE model) \n",
        "\n",
        "* Dataset 6: Preprocessed + Feature selection + Dimensionality Reduction (Putting fs_df through best Dim Red function)\n",
        "\n",
        "* Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction (putting FE model through  best Dim Red function)\n",
        "\n",
        "* Dataset 8: Preprocessed + Feature Engineering + Feature Selection (putting dataset 5 through best Dim Red function)"
      ],
      "metadata": {
        "id": "45Wd1ZdbmT71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1: Linear Regression**\n"
      ],
      "metadata": {
        "id": "MGN3ScgOoPV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1: Preprocessed Only"
      ],
      "metadata": {
        "id": "KDk3wjzTknGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), ppr_df)"
      ],
      "metadata": {
        "id": "l9Jc-LaVoa8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2: Preprocessed + Feature Engineering"
      ],
      "metadata": {
        "id": "kyJvbCJuofbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "6pmqwg4OokE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3: Preprocessed + Feature Selection"
      ],
      "metadata": {
        "id": "yyZNNng9oqdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), fs_df)"
      ],
      "metadata": {
        "id": "VddxIf8Aouoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 4: Preprocessed + Dimensionality Reduction"
      ],
      "metadata": {
        "id": "XsaV-K23o0av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LinearRegression(), ppr_df, 134)"
      ],
      "metadata": {
        "id": "cnYQR4eNo4mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 5: Preprocessed + Feature Engineering + Feature Selection"
      ],
      "metadata": {
        "id": "fhf_DKYLu-08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_fs_df = feature_selection(ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "p1KaAITAvE-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), fe_fs_df)"
      ],
      "metadata": {
        "id": "UWIKd1VfvUb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 6: Preprocessed + Feature Selection + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fs_df. As it turns out, it's PCA with 165 features"
      ],
      "metadata": {
        "id": "rHSsoGGNvZ3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LinearRegression(), fs_df, 219) #don't need to run this if you trust that I've run this already and discovers that 165 returns the best results"
      ],
      "metadata": {
        "id": "VNv9vT9Uvgwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LinearRegression(), fs_df, 165)"
      ],
      "metadata": {
        "id": "ujhmijW2wGky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fs_df = mca(fs_df)\n",
        "regressor(LinearRegression(), mca_fs_df)"
      ],
      "metadata": {
        "id": "PLFw6bk7wGk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LinearRegression(), fs_df)"
      ],
      "metadata": {
        "id": "nUQ0Ev2GwGk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's PCA with 101 features\n"
      ],
      "metadata": {
        "id": "4u1wHcO6wumA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LinearRegression(), ppr_dr_ro_af_df, 130) #don't need to run this if you trust that I've run this already and discovers that 101 returns the best results"
      ],
      "metadata": {
        "id": "g9g6VQ3cw1mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LinearRegression(), ppr_dr_ro_af_df, 101)"
      ],
      "metadata": {
        "id": "UYQ-lwLJw1m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_ppr_dr_ro_af_df = mca(ppr_dr_ro_af_df)\n",
        "regressor(LinearRegression(), mca_ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "yd8-st40w1m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LinearRegression(), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "MGGz8_9Sw1m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 8: Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fe_fs_df. As it turns out, it's PCA with 128 features\n"
      ],
      "metadata": {
        "id": "lpJCkoq9x7Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LinearRegression(), fe_fs_df, 250) #don't need to run this if you trust that I've run this already and discovers that 128 returns the best results"
      ],
      "metadata": {
        "id": "6Se9I9x4x7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LinearRegression(), fe_fs_df, 128)"
      ],
      "metadata": {
        "id": "KiKZg8oVx7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fe_fs_df = mca(fe_fs_df)\n",
        "regressor(LinearRegression(), mca_fe_fs_df)"
      ],
      "metadata": {
        "id": "Hm54HUwZx7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LinearRegression(), fe_fs_df)"
      ],
      "metadata": {
        "id": "XRn4TB7Yx7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2: RidgeCV**\n"
      ],
      "metadata": {
        "id": "rbA6LbeAyvcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1: Preprocessed Only"
      ],
      "metadata": {
        "id": "bRtEHD7WkhCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(RidgeCV(), ppr_df)"
      ],
      "metadata": {
        "id": "EdNzt4OvyvcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2: Preprocessed + Feature Engineering"
      ],
      "metadata": {
        "id": "x1DmxnmxyvcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(RidgeCV(), ppr_ro_af_df)"
      ],
      "metadata": {
        "id": "jmfyTejWyvcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3: Preprocessed + Feature Selection"
      ],
      "metadata": {
        "id": "ZlgNyrz-yvcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(RidgeCV(), fs_df)"
      ],
      "metadata": {
        "id": "uXfpW5lvyvcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 4: Preprocessed + Dimensionality Reduction"
      ],
      "metadata": {
        "id": "zrIhFibpyvcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(RidgeCV(), ppr_df, 134)"
      ],
      "metadata": {
        "id": "SgdiX-4fyvcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 5: Preprocessed + Feature Engineering + Feature Selection\n",
        "note: while RidgeCV had a different better performing Feature Engineering dataset compared to Linear Regression and LassoCV (ppr_ro_af_df instead of ppr_dr_ro_af_df), we are using the full feature engineering to combine with feature selection, as that seems more complete and it doesn't crash."
      ],
      "metadata": {
        "id": "_KB5l1nKyvcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(RidgeCV(), fe_fs_df)"
      ],
      "metadata": {
        "id": "M27LRvfYyvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 6: Preprocessed + Feature Selection + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fs_df. As it turns out, it's PCA with 202 features"
      ],
      "metadata": {
        "id": "_s8pFIwByvcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(RidgeCV(), fs_df, 219) #don't need to run this if you trust that I've run this already and discovers that 202 returns the best results"
      ],
      "metadata": {
        "id": "70HdQtplyvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(RidgeCV(), fs_df, 202)"
      ],
      "metadata": {
        "id": "hQ6PU3ADyvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fs_df = mca(fs_df)\n",
        "regressor(RidgeCV(), mca_fs_df)"
      ],
      "metadata": {
        "id": "IWpUZNb-yvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(RidgeCV(), fs_df)"
      ],
      "metadata": {
        "id": "L1i4-j2pyvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_ro_af_df. As it turns out, it's PCA with 129 features\n"
      ],
      "metadata": {
        "id": "x7eVVKFjyvcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(RidgeCV(),  ppr_ro_af_df, 130) #don't need to run this if you trust that I've run this already and discovers that 129 returns the best results"
      ],
      "metadata": {
        "id": "8ZTRBcN5yvcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(RidgeCV(),  ppr_ro_af_df, 129)"
      ],
      "metadata": {
        "id": "MeSl8XkyyvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_ppr_ro_af_df= mca(ppr_ro_af_df)\n",
        "regressor(RidgeCV(), mca_ppr_ro_af_df)"
      ],
      "metadata": {
        "id": "5tiUJyrAyvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(RidgeCV(), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "q_H6-nQvyvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 8: Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fe_fs_df. As it turns out, it's PCA with 210 features\n"
      ],
      "metadata": {
        "id": "Ol9g6anMyvcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(RidgeCV(), fe_fs_df, 250) #don't need to run this if you trust that I've run this already and discovers that 210 returns the best results"
      ],
      "metadata": {
        "id": "ahzjMccQyvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(RidgeCV(), fe_fs_df, 210)"
      ],
      "metadata": {
        "id": "yINzUuYWyvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fe_fs_df = mca(fe_fs_df)\n",
        "regressor(RidgeCV(), mca_fe_fs_df)"
      ],
      "metadata": {
        "id": "kQyEaG1pyvcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(RidgeCV(), fe_fs_df)"
      ],
      "metadata": {
        "id": "2TM5YjIWyvcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 3: LassoCV**\n"
      ],
      "metadata": {
        "id": "ZZhxDUv_17La"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1: Preprocessed Only"
      ],
      "metadata": {
        "id": "GmueIXw0kGPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LassoCV(), ppr_df)"
      ],
      "metadata": {
        "id": "c6scm8oZ17Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2: Preprocessed + Feature Engineering"
      ],
      "metadata": {
        "id": "tmQub9z217Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LassoCV(), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "fLKrSV6y17Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3: Preprocessed + Feature Selection"
      ],
      "metadata": {
        "id": "F8ePCQa317Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LassoCV(), fs_df)"
      ],
      "metadata": {
        "id": "RISWlGG517Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 4: Preprocessed + Dimensionality Reduction"
      ],
      "metadata": {
        "id": "d-pf6M6L17Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LassoCV(), ppr_df, 262)"
      ],
      "metadata": {
        "id": "CNvYMz1H17Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 5: Preprocessed + Feature Engineering + Feature Selection"
      ],
      "metadata": {
        "id": "umDQcMhP17Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_fs_df = feature_selection(ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "l4o_M7vT17Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LassoCV(), fe_fs_df)"
      ],
      "metadata": {
        "id": "Gcd6ISdC17Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 6: Preprocessed + Feature Selection + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fs_df. As it turns out, it's FAMD"
      ],
      "metadata": {
        "id": "h7u8NR2C17Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LassoCV(), fs_df, 219) #don't need to run this if you trust that I've run this already and discovers that 219 returns the best results"
      ],
      "metadata": {
        "id": "clCukjlo17Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LassoCV(), fs_df, 219)"
      ],
      "metadata": {
        "id": "E0zLyuAI17Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fs_df = mca(fs_df)\n",
        "regressor(LassoCV(), mca_fs_df)"
      ],
      "metadata": {
        "id": "R_eY1aZT17Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LassoCV(), fs_df)"
      ],
      "metadata": {
        "id": "tjNMMJG817Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's PCA with 130 features\n"
      ],
      "metadata": {
        "id": "tbZbVkxz17Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LassoCV(), ppr_dr_ro_af_df, 130) #don't need to run this if you trust that I've run this already and discovers that 130 returns the best results"
      ],
      "metadata": {
        "id": "eF_f-VZ-17Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LassoCV(), ppr_dr_ro_af_df, 128)"
      ],
      "metadata": {
        "id": "Ac7HFduz17Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_ppr_dr_ro_af_df = mca(ppr_dr_ro_af_df)\n",
        "regressor(LassoCV(), mca_ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "AoyYcqLX17Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LassoCV(), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "tO44JuhJ17Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 8: Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's FAMD\n"
      ],
      "metadata": {
        "id": "RkbDL01417Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(LassoCV(), fe_fs_df, 250) #don't need to run this if you trust that I've run this already and discovers that 250 returns the best results"
      ],
      "metadata": {
        "id": "NsYq74Kn17Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(LassoCV(), fe_fs_df, 249)"
      ],
      "metadata": {
        "id": "CXPOB91D17Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fe_fs_df = mca(fe_fs_df)\n",
        "regressor(LassoCV(), mca_fe_fs_df)"
      ],
      "metadata": {
        "id": "C0f-JhwR17Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(LassoCV(), fe_fs_df)"
      ],
      "metadata": {
        "id": "-HBGIWMt17Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 4: AdaBoost**\n"
      ],
      "metadata": {
        "id": "jBXn2ycCMZDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1: Preprocessed Only\n",
        "\n",
        "Haven't run this yet, so all the text results are incomplete"
      ],
      "metadata": {
        "id": "x75f_lpSkJQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_df)"
      ],
      "metadata": {
        "id": "Wjc5jSgVMZDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2: Preprocessed + Feature Engineering"
      ],
      "metadata": {
        "id": "V0Ch9BFdMZDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "AV8Ex-7uMZDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3: Preprocessed + Feature Selection"
      ],
      "metadata": {
        "id": "m-cUbYo_MZDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fs_df)"
      ],
      "metadata": {
        "id": "RqolMvPRMZDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 4: Preprocessed + Dimensionality Reduction"
      ],
      "metadata": {
        "id": "nu0fz5jUMZDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), mca_df)"
      ],
      "metadata": {
        "id": "f5_WahNAMZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 5: Preprocessed + Feature Engineering + Feature Selection"
      ],
      "metadata": {
        "id": "W6tTFpVFMZDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_fs_df = feature_selection(ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "p-A4kphTMZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fe_fs_df)"
      ],
      "metadata": {
        "id": "DuRTdb6ZMZDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 6: Preprocessed + Feature Selection + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fs_df. As it turns out, it's FAMD"
      ],
      "metadata": {
        "id": "qEq6HM4FMZDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fs_df, 219) #don't need to run this if you trust that I've run this already and discovers that 219 returns the best results"
      ],
      "metadata": {
        "id": "BIfX7BMJMZDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fs_df, 219)"
      ],
      "metadata": {
        "id": "xC7_nrQrMZDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fs_df = mca(fs_df)\n",
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), mca_fs_df)"
      ],
      "metadata": {
        "id": "agrLo8f9MZDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fs_df)"
      ],
      "metadata": {
        "id": "E0fOvSyaMZDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's PCA with 128 features\n"
      ],
      "metadata": {
        "id": "6k304b8OMZDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_dr_ro_af_df, 128) #don't need to run this if you trust that I've run this already and discovers that 130 returns the best results"
      ],
      "metadata": {
        "id": "e0baidpjMZDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_dr_ro_af_df, 128)"
      ],
      "metadata": {
        "id": "FitIr5HCMZDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_ppr_dr_ro_af_df = mca(ppr_dr_ro_af_df)\n",
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), mca_ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "-TQjJRjWMZDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "6yiqe-WkMZDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 8: Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's PCA with 249 features\n"
      ],
      "metadata": {
        "id": "A_umz4moMZDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fe_fs_df, 250) #don't need to run this if you trust that I've run this already and discovers that 250 returns the best results"
      ],
      "metadata": {
        "id": "BV8Q-A_bMZDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fe_fs_df, 249)"
      ],
      "metadata": {
        "id": "9touOgL9MZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fe_fs_df = mca(fe_fs_df)\n",
        "regressor(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), mca_fe_fs_df)"
      ],
      "metadata": {
        "id": "RVnENaiHMZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(AdaBoostRegressor(n_estimators= 100, learning_rate = 1), fe_fs_df)"
      ],
      "metadata": {
        "id": "u0HejP04MZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 5: XGBoost**\n",
        "\n"
      ],
      "metadata": {
        "id": "RxDpt7vm3dIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1: Preprocessed Only"
      ],
      "metadata": {
        "id": "yphT4U75kRYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_df)"
      ],
      "metadata": {
        "id": "acYwJVaX3dIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2: Preprocessed + Feature Engineering"
      ],
      "metadata": {
        "id": "Eu6ZsKLL3dIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_ro_af_df)"
      ],
      "metadata": {
        "id": "5a4LuHST3dIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3: Preprocessed + Feature Selection"
      ],
      "metadata": {
        "id": "x7oSizgd3dIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fs_df)"
      ],
      "metadata": {
        "id": "2NuGKoMt3dIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 4: Preprocessed + Dimensionality Reduction"
      ],
      "metadata": {
        "id": "YQzdw92l3dIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_df, 262)"
      ],
      "metadata": {
        "id": "-7BRw7-O3dIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 5: Preprocessed + Feature Engineering + Feature Selection"
      ],
      "metadata": {
        "id": "FkFe1jwT3dIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_fs_df = feature_selection(ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "KtJB7I3F3dIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fe_fs_df)"
      ],
      "metadata": {
        "id": "0lBPZHQV3dIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 6: Preprocessed + Feature Selection + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the fs_df. As it turns out, it's PCA with 171 features"
      ],
      "metadata": {
        "id": "8gEqqrNC3dIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fs_df, 219) #don't need to run this if you trust that I've run this already and discovers that 171 returns the best results"
      ],
      "metadata": {
        "id": "ZeR6IwbM3dIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fs_df, 171)"
      ],
      "metadata": {
        "id": "jHyopCls3dIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_fs_df = mca(fs_df)\n",
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), mca_fs_df)"
      ],
      "metadata": {
        "id": "TECOEg5H3dIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fs_df)"
      ],
      "metadata": {
        "id": "X6CSwSoi3dIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 7: Preprocessed + Feature Engineering + Dimensionality Reduction\n",
        "\n",
        "For this we need to test the 3 different Dim Red methods again to see which one applies best with the ppr_dr_ro_af_df. As it turns out, it's PCA with 128 features\n"
      ],
      "metadata": {
        "id": "27exaOzp3dIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_evaluation(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_dr_ro_af_df, 128) #don't need to run this if you trust that I've run this already and discovers that 128 returns the best results"
      ],
      "metadata": {
        "id": "MJAqXFo53dIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_dr_ro_af_df, 128)"
      ],
      "metadata": {
        "id": "MKJdz-we3dIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mca_ppr_dr_ro_af_df = mca(ppr_dr_ro_af_df)\n",
        "regressor(XGBRegressor(booster='gbtree', objective='reg:squarederror'), mca_ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "S-pP4QTM3dIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Famd(XGBRegressor(booster='gbtree', objective='reg:squarederror'), ppr_dr_ro_af_df)"
      ],
      "metadata": {
        "id": "ro9D223l3dIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca(XGBRegressor(booster='gbtree', objective='reg:squarederror'), fe_fs_df, 128)"
      ],
      "metadata": {
        "id": "38wLh8bxblDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**\n",
        "\n",
        "Here's a table with the results we find for the validation scores.  "
      ],
      "metadata": {
        "id": "AqNZYCZAioBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results= [[0.864049256666222, 0.882993788411652, 0.57307520746678, 0.88675026673289, 0.562444946440133, 0.570734722689366, 0.885061238332195, 0.572579970161637 ],\n",
        "          [0.929792769342271,0.889912655333249, 0.564117682743432, 0.887531961995074, 0.560001523399702, 0.56555931546625,  0.887031269852025, 0.562285091841353 ],\n",
        "          [0.79497251266111, 0.795964920104688, 0.385353999499943, 0.792961241847281, 0.385353503248167, 0.459591797446816, 0.791585588001044, 0.413759820106853  ],\n",
        "          [0.013888888888888888, 0.013888888888888888,0.013793103448275862,0.006944444444444444,0.013793103448275862,  0.013793103448275862, 0.010380622837370242, 0.020618556701030927],\n",
        "          [0.8874144692240529,0.8939285305481581, 0.6756744674642111,0.8188901089366438, 0.6403642344872913, 0.6728817403925524, 0.8448092641012978,0.7164264936286864   ]]\n",
        "index= ['PP', 'PP+FE', 'PP+FS', 'PP+DR', 'PP+FE+FS', 'PP+FS+DR', 'PP+FE+DR', 'PP+FS+FE+DR']\n",
        "dfs = ['Linear Regression','RidgeCV','LassoCV', 'AdaBoost', 'XGBoost']\n",
        "pd.DataFrame(results, columns = index, index = dfs)"
      ],
      "metadata": {
        "id": "J6lzCukAipyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Auto SkLearn Comparison**\n",
        "\n",
        "As we're using Auto-sklearn as a comparison at the end and the installation of auto-sklearn gives an error with the fs_df creation, we're going to install auto-sklearn now here at the end. \n",
        "\n",
        "Note that for the installation to be completed, you need to restart the runtime, so there will be some duplicate code cells underneath such that you can run those and not have worry about going back through the notebook again"
      ],
      "metadata": {
        "id": "nVSbP-c8y8Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install auto-sklearn"
      ],
      "metadata": {
        "id": "LJ7pJWPcKzXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duplicate functions\n",
        "These are code cells we've seen before, but need now after restarting the runtime. It's recommended to run these and then collapse the header\n"
      ],
      "metadata": {
        "id": "mYjjeI9I993V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv6mmG98-PDu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import prince\n",
        "import scipy\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy.special import boxcox1p\n",
        "from scipy import stats\n",
        "from math import ceil\n",
        "from scipy.stats import probplot\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LogisticRegression\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.preprocessing import power_transform\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import metrics\n",
        "from numpy import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://drive.google.com/file/d/1_PLO-CF84thdpb-dMlE8y24nEyH-g7qh/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "init_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "rMEp_2jj-IFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df is a copy of the initial df so we don't have to redownload many times\n",
        "df = init_df.copy()"
      ],
      "metadata": {
        "id": "jebmJniJ-IFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First divide data into the numerical or categorical, so we can preprocess it\n",
        "\n",
        "# List of nominal and ordinal columns extracted from data_description.txt\n",
        "nom_col = ['MSSubClass', 'MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1',\n",
        "           'Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n",
        "           'BsmtFinType1','BsmtFinType2','Electrical','FireplaceQu','PavedDrive','Fence','SaleCondition',\n",
        "           'MasVnrType','Foundation','Heating','CentralAir','GarageType','SaleType','MiscFeature',\n",
        "           # Month sold and Year should be considered nominal, as they can have \n",
        "           # an effect on sale price (price fluctuations or whatever), but not\n",
        "           # on an ordinal scale\n",
        "           'MoSold' , 'YrSold'\n",
        "           ]\n",
        "\n",
        "ord_col = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\n",
        "           'HeatingQC','KitchenQual','Functional',\n",
        "           'GarageFinish','GarageQual','GarageCond','PoolQC','OverallQual','OverallCond',\n",
        "           # The following are added as ordinal features because they have a\n",
        "           # very low number of discrete categories, and it intuitively makes\n",
        "           # sense to consider 2 fullbaths better than 1.\n",
        "           'BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n",
        "           'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars'\n",
        "           ]\n",
        "\n",
        "# The following are not used and are left out on purpose. They contain only\n",
        "# 7 measurements, and far too many NaNs to easily be used.\n",
        "# Alternatively, they could be one-hot encoded so that abundance of NaN or '0'\n",
        "# will not impact the regression algorithms as negatively.\n",
        "# Another alternative could be to create a new nominal feature of whether a\n",
        "# house has a pool or not, or [no pool, average pool, nice pool].\n",
        "not_usable = ['PoolQC' , 'PoolArea',]\n",
        "\n",
        "# List of all columns\n",
        "allcat = list(df.columns[1:])\n",
        "\n",
        "# List of numerical columns\n",
        "num_col = [x for x in allcat if x not in nom_col+ord_col]"
      ],
      "metadata": {
        "id": "6ocu-1M7-IFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def impute(input):\n",
        "    # Only used for LotFrontage to avoid too much imputation causeing inaccuracy\n",
        "    imp = IterativeImputer(n_nearest_features=None, imputation_order='ascending')\n",
        "    imp.fit(input)\n",
        "    output = pd.DataFrame(imp.transform(input), columns = input.columns)\n",
        "    return output\n",
        "\n",
        "\n",
        "def fixnan(input):\n",
        "    # Fix the garage year built - Inputting 0 would put it very far below all\n",
        "    # other houses, so instead if there is no garage, simply input the year\n",
        "    # the house was built in the garage year built column.\n",
        "    input.loc[input.GarageYrBlt.isnull(),'GarageYrBlt'] = input.loc[input.GarageYrBlt.isnull(),'YearBuilt']\n",
        "\n",
        "    # Drop the single row with NaN in 'Electrical' since this is a missing \n",
        "    # measurement. Additionally, drop the rows related to the masonry that\n",
        "    # contain NaN values, as these are also missing measurements, and there are\n",
        "    # only a few of them, less than 10 rows.\n",
        "    input.dropna(subset = ['Electrical','MasVnrType','MasVnrArea'], inplace=True)\n",
        "\n",
        "    # Fix MasVnrArea as it is for some reason an object type\n",
        "    input.MasVnrArea = input.MasVnrArea.astype(str).astype(float)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "def fillnan(input, remlf=1):\n",
        "    # Fill NaNs\n",
        "    for col in nom_col:\n",
        "        input[col].fillna('None',inplace=True)\n",
        "    for col in ord_col:\n",
        "        input[col].fillna('None',inplace=True)\n",
        "\n",
        "    # Remove LotFrontage from list of columns to fill. We don't want to fill \n",
        "    # this, as it is a continuous numerical measurement we can fill with \n",
        "    # multivariate imputation instead, to benefit our models accuracy\n",
        "    col_num_nan = num_col.copy()\n",
        "    if remlf is 1:\n",
        "        try: col_num_nan.remove('LotFrontage')\n",
        "        except: pass\n",
        "    for col in col_num_nan:\n",
        "        input[col].fillna('0',inplace=True)\n",
        "    return input\n",
        "\n",
        "\n",
        "def preprocess(df, remlf=1):\n",
        "    df.drop(not_usable, axis=1)\n",
        "    df = fixnan(df)\n",
        "    df = fillnan(df, remlf)\n",
        "\n",
        "    # Split nominal, ordinal, and numerical columns\n",
        "    df_nom = df[nom_col]\n",
        "    df_ord = df[ord_col]\n",
        "    df_num = df.drop(list(nom_col+ord_col), axis=1)\n",
        "\n",
        "    # One-hot encode nominal columns\n",
        "    df_nom = pd.get_dummies(data=df_nom)\n",
        "    df_MSSubClass = pd.get_dummies(data=df.MSSubClass, prefix='MSSubClass', prefix_sep='_')\n",
        "\n",
        "    # Map ordinal columns\n",
        "    df_ord.BsmtExposure = df_ord.BsmtExposure.replace({'NA' : 0, 'No' : 0, 'Mn' : 1, 'Av' : 2, 'Gd' : 3})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 5})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'None' : 0,  'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5})\n",
        "    df_ord = df_ord.replace({'IR3' : 0, 'IR2' : 1, 'IR1' : 2, 'Reg' : 3})\n",
        "    df_ord = df_ord.replace({'Low' : 0, 'HLS' : 1, 'Bnk' : 2, 'Lvl' : 3})\n",
        "    df_ord = df_ord.replace({'Gtl' : 0, 'Mod' : 1, 'Sev' : 2})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'Lwq' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6})\n",
        "    df_ord = df_ord.replace({'Sal' : 0, 'Sev' : 1, 'Maj2' : 2, 'Maj1' : 3, 'Mod' : 4, 'Min2' : 5, 'Min1' : 6, 'Typ' : 7})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3})\n",
        "    df_ord = df_ord.replace({'N' : 0, 'P' : 1, 'Y' : 2})\n",
        "    df_ord = df_ord.replace({'ELO' : 0, 'NoSeWa' : 1, 'NoSewr' : 2, 'AllPub' : 3})\n",
        "\n",
        "    # Merge nominal, ordinal, and numerical back together\n",
        "    df = pd.concat([df_num, df_MSSubClass, df_nom, df_ord], axis=1)\n",
        "    df = df.drop(\"MSSubClass\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "yh2BH4AH-IFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset which only removes NaNs, labels columns for ordirnal/nominal data and int/float data for the Auto Sklearn dataset.\n",
        "ppr_auto_df = preprocess(df, remlf=0)\n",
        "ppr_auto_df['LotFrontage'] = ppr_auto_df['LotFrontage'].astype('int')"
      ],
      "metadata": {
        "id": "tFQ2DCeM-IFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  split(df, val_frac=0.2, seed=1):\n",
        "    # Validation set is a sample of val_frac size. Deafult is 0.2, or 20%. \n",
        "    # Seed is either 0 for no seed, 1 for default seed, or a real number as seed.\n",
        "    if seed == 0:\n",
        "        val = df.sample(frac=val_frac)\n",
        "    if seed == 1: \n",
        "        val = df.sample(frac=val_frac, random_state=200)\n",
        "    else:\n",
        "        val = df.sample(frac=val_frac, random_state=seed)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "    return train, val"
      ],
      "metadata": {
        "id": "5T41NT8M-IFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto Sklearn Continued\n",
        "\n",
        "As we do the Auto Sklearn, we will need the \"autoskl_reg.pkl\" file which can be found in the MachineLearning/Project/Files. \n",
        "\n",
        "For you the path may be different, as this folder will be on your shared drives, so check the left side of Google Collab and see the file icon. This opens your file directory of Collab. \n",
        "\n",
        "Follow content/drive/Shareddrives and then search for the \"autoskl_reg.pkl\" and use the 3 dots at the end to copy path and paste it over my path. \n",
        "\n",
        "If you have trouble accessing the SharedDrives, you can always download the \"autoskl_reg.pkl\" file and upload it to your own drive and then do the same steps to access its path"
      ],
      "metadata": {
        "id": "6UPKiVD7-nAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import r2_score\n",
        "import pickle"
      ],
      "metadata": {
        "id": "5uT_i3j-Cxpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare df for model\n",
        "df = ppr_auto_df.copy()\n",
        "\n",
        "for col in num_col:\n",
        "    df[col] = df[col].astype('int')\n",
        "for col in df.columns:\n",
        "    if col not in num_col:\n",
        "        df[col] = df[col].astype('category')\n",
        "#df = df.drop([\"MiscFeature_TenC\"], axis=1)\n",
        "\n",
        "train, val = split(df, 0.2, 210)\n",
        "valx = val.drop(['SalePrice'], axis=1)\n",
        "valy = val.SalePrice"
      ],
      "metadata": {
        "id": "LJnoeIpKCxwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load auto-sklearn model\n",
        "with open('autoskl_reg.pkl', 'rb') as f:\n",
        "    autoskl_regressor = pickle.load(f)"
      ],
      "metadata": {
        "id": "VK454LyhC3zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "y_true = valy\n",
        "y_pred = autoskl_regressor.predict(valx)\n",
        "print('auto-sklearn regressor log MSE:', mean_squared_log_error(y_true, y_pred))\n",
        "print()\n",
        "print('auto-sklearn regressor validation score:', r2_score(y_true, y_pred))\n",
        "print()\n",
        "qmin = np.quantile(y_true, [0.0])\n",
        "qmax = np.quantile(y_true, [1.0])\n",
        "\n",
        "plt.scatter(autoskl_regressor.predict(valx), y_true, marker = \"o\",  c = \"blue\")\n",
        "#plt.scatter(autoskl_regressor.predict(valx), y_pred, marker = \"o\",  c = \"green\", label = \"Predicted Y\")\n",
        "plt.plot([qmin, qmax], [qmin, qmax], color = 'red')\n",
        "plt.title(\"Auto-sklearn Regressor\")\n",
        "plt.xlabel(\"Predicted values\")\n",
        "plt.ylabel(\"Real values\")\n",
        "plt.legend(loc = \"upper left\")\n",
        "\n",
        "print(mean_squared_log_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "f_-W4BerC5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_int(y_true, y_pred)"
      ],
      "metadata": {
        "id": "RrPjtMXNYFUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_mean = [ppr_df.SalePrice.mean() for i in y_true]\n",
        "base_median = [ppr_df.SalePrice.median() for i in y_true]\n",
        "\n",
        "print(mean_squared_log_error(y_true, base_mean))\n",
        "print(mean_squared_log_error(y_true, base_median))"
      ],
      "metadata": {
        "id": "ZS32_4eNo4Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.api as sms"
      ],
      "metadata": {
        "id": "JsLKkLbfpAqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy"
      ],
      "metadata": {
        "id": "WQUokuCtE2JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " a = mean_squared_log_error(y_true, y_pred, multioutput='raw_values')\n",
        " sms.DescrStatsW(a).tconfint_mean()"
      ],
      "metadata": {
        "id": "nu_941vVpkLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_squared_log_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "M0kPPUnA_wgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  std_err(y_true, y_pred):   \n",
        "    error = []\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        error.append(mean_squared_log_error([true], [pred]))\n",
        "\n",
        "    std_err = scipy.stats.bootstrap((error,), np.mean, method='basic').standard_error   \n",
        "    return std_err\n",
        "\n",
        "def  conf_int(y_true, y_pred):   \n",
        "    error = []\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        error.append(mean_squared_log_error([true], [pred]))\n",
        "\n",
        "    conf_int = scipy.stats.bootstrap((error,), np.mean, method='basic').confidence_interval   \n",
        "    return conf_int"
      ],
      "metadata": {
        "id": "Txpizbra_0Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data set with bare minimum preprocessing\n"
      ],
      "metadata": {
        "id": "N_RyzEEKE4-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  min_prep(df):\n",
        "    df.MasVnrArea = df.MasVnrArea.astype(str).astype(float)\n",
        "    df = fillnan(df, 0)\n",
        "    # Split nominal, ordinal, and numerical columns\n",
        "    df_nom = df[nom_col]\n",
        "    df_ord = df[ord_col]\n",
        "    df_num = df.drop(list(nom_col+ord_col), axis=1)\n",
        "\n",
        "    # One-hot encode nominal columns\n",
        "    df_nom = pd.get_dummies(data=df_nom)\n",
        "    df_MSSubClass = pd.get_dummies(data=df.MSSubClass, prefix='MSSubClass', prefix_sep='_')\n",
        "\n",
        "    # Map ordinal columns\n",
        "    df_ord.BsmtExposure = df_ord.BsmtExposure.replace({'NA' : 0, 'No' : 0, 'Mn' : 1, 'Av' : 2, 'Gd' : 3})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 5})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'None' : 0,  'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5})\n",
        "    df_ord = df_ord.replace({'IR3' : 0, 'IR2' : 1, 'IR1' : 2, 'Reg' : 3})\n",
        "    df_ord = df_ord.replace({'Low' : 0, 'HLS' : 1, 'Bnk' : 2, 'Lvl' : 3})\n",
        "    df_ord = df_ord.replace({'Gtl' : 0, 'Mod' : 1, 'Sev' : 2})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'Lwq' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6})\n",
        "    df_ord = df_ord.replace({'Sal' : 0, 'Sev' : 1, 'Maj2' : 2, 'Maj1' : 3, 'Mod' : 4, 'Min2' : 5, 'Min1' : 6, 'Typ' : 7})\n",
        "    df_ord = df_ord.replace({'NA' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3})\n",
        "    df_ord = df_ord.replace({'N' : 0, 'P' : 1, 'Y' : 2})\n",
        "    df_ord = df_ord.replace({'ELO' : 0, 'NoSeWa' : 1, 'NoSewr' : 2, 'AllPub' : 3})\n",
        "\n",
        "    # Merge nominal, ordinal, and numerical back together\n",
        "    df = pd.concat([df_num, df_MSSubClass, df_nom, df_ord], axis=1)\n",
        "    df = df.drop(\"MSSubClass\", axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "UjO4H3AdLTD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = init_df.copy()\n",
        "\n",
        "min_df = min_prep(df)"
      ],
      "metadata": {
        "id": "T0DAN2_AGLXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_df.isna().sum()"
      ],
      "metadata": {
        "id": "dT993J01GPQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor(LinearRegression(), min_df)"
      ],
      "metadata": {
        "id": "2DNGcqiYFhqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regressor(models, df, cols, drop=['SalePrice'], target=['SalePrice']):\n",
        "    # Validation set is a sample of 20%. Seed is used to get consistent results while testing\n",
        "    val = df.sample(frac=0.2,random_state=200)\n",
        "    # training is set acquired by dropping the validation set\n",
        "    train = df.drop(val.index)\n",
        "\n",
        "    x_col = train.drop(drop, axis=1)\n",
        "    X = x_col.values.reshape(-1, len(x_col.columns))\n",
        "    y = ravel(train[target].values)\n",
        "\n",
        "    idx = [\"Train r2\", \"val r2\", \"train log\", \"val log\", \"val std err\"]\n",
        "    train_r2_score = []\n",
        "    val_r2_result = []\n",
        "    train_log_score = []\n",
        "    val_log_score = []\n",
        "    val_std_err = []\n",
        "\n",
        "    for model in models:\n",
        "        reg = model.fit(X, y)\n",
        "        valx_col = val.drop(drop, axis=1)\n",
        "        valx = valx_col.values.reshape(-1, len(valx_col.columns))\n",
        "        valy = ravel(val[target].values)\n",
        "        train_r2_score.append(reg.score(X, y))\n",
        "        val_r2_result.append(reg.score(valx, valy))\n",
        "        train_log_score.append(sklearn.metrics.mean_squared_log_error(reg.predict(X), y))\n",
        "        val_log_score.append(sklearn.metrics.mean_squared_log_error(reg.predict(valx), valy))\n",
        "        val_std_err.append(std_err(valy, reg.predict(valx)))\n",
        "        print(str(model), conf_int(valy, reg.predict(valx)))\n",
        "\n",
        "    output = pd.DataFrame([train_r2_score, val_r2_result, train_log_score, val_log_score, val_std_err], index=idx, columns=cols)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ny5YCv6fF6f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [LinearRegression(), \n",
        "          RidgeCV(), \n",
        "          LassoCV(), \n",
        "          AdaBoostRegressor(n_estimators= 100, learning_rate = 1), \n",
        "          XGBRegressor(booster='gbtree', objective='reg:squarederror')\n",
        "          ]\n",
        "\n",
        "columns = [\"Linear Regression\", \n",
        "           \"RidgeCV\", \n",
        "           \"LassoCV\",\n",
        "           \"AdaBoost\",\n",
        "           \"XGBoost\"\n",
        "           ]"
      ],
      "metadata": {
        "id": "ycj2Z2j1Jcz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = regressor(models, min_df, columns)"
      ],
      "metadata": {
        "id": "zMhcoMwPJDYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NX3raKqkXhvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "id": "5yT4PlPoJoH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = regressor([XGBRegressor(booster='gbtree', objective='reg:squarederror')], min_df, [\"XGBoost\"])"
      ],
      "metadata": {
        "id": "K29mL8HdW_Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb"
      ],
      "metadata": {
        "id": "wX5V13xmXL1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sQGEd_EcXMrS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}